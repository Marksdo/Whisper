# Connect LLM with Whisper Mate (Experimental) 
- embed chat with openai gpt inside Whisper Mate
- you can deploy litellm to proxy to other llm service (response with openai chat text format)



> todo not finish document